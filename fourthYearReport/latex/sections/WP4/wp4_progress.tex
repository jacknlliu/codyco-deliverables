%!TEX root = ../../fourthYearReport.tex


\paragraph{Work package 4 progress}

The progress for each task are described hereafter.

\subparagraph*{Improved Models from Real-Time Regression with Latent Contact Type Inference (T4.1)}

\input{sections/WP4/wp4_progress_T41_IIT}

\subparagraph*{Inferring the Operational Space and Appropriate Controls with Multiple Contacts (T4.2)}

\input{sections/WP4/wp4_progress_T42_IIT}

\subparagraph{Learning the Prioritization of Tasks (T4.4) (TUD: 4PM)}

TUD continued its research on learning task prioritizations from human demonstrations using probabilistic models. This work is currently under review and 
a draft of the paper was added to Deliverable D4.3 in Section 5.  Here is a short summary of the approach. 

Movement prioritization is a common approach
to combine controllers of different tasks for redundant robots.
Each task is assigned a priority, where either strict or 'soft'
priorities can be used. While movement prioritization is an
important concept in the control of whole body movements, it
has been less considered in learning-based approaches, where
prioritization allows us to learn different tasks for different
end-effectors, and subsequently reproduce an arbitrary, unseen
combination of these tasks. This paper combines Bayesian task
prioritization, a 'soft' prioritization technique, with probabilistic
movement primitives to prioritize full motion sequences.
Probabilistic movement primitives can encode distributions of
movements over full motion sequences and provide control
laws to exactly follow these distributions. The probabilistic
formulation allows for a natural application of Bayesian task
prioritization. We demonstrate how the 'soft' priorities can
be obtained from imitation learning and that our prioritized
learning architecture can reproduce unseen task-combinations.
Moreover, we require less data to learn a combination of tasks
than the traditional approach that directly models each task in
joint space. We evaluate our approach on reaching movements
under constraints with a redundant bi-manual planar robot
and the humanoid robot iCub. 

\subparagraph{Learning the Prioritization of Tasks (T4.4) (INRIA: 4.02PM)}

INRIA continued its research on automatically learning soft task priorities (or task weights) using stochastic optimization algorithms. The research is presented in Deliverable D4.3. 

The motivation for the work was to provide an automatic way of determining the temporal profile of the soft task priorities, that are classically manually tuned by experts. When done manually, the critical issue is to define the task transitions, i.e., to define when a task becomes ``less important'' and its weight diminishes, and viceversa.

In a first paper \cite{Modugno_PICRA_2016}, in collaboration with TUD, we investigated how to learn the temporal profile of the soft task priorities (or task weights) in a reinforcement learning scenario. We represented the soft task priorities with parametrized weight functions, and used CMA-ES (Covariance Matrux Adaptation Evolution Strategy, a state-of-the-art blakc-box stochastic optimization algorithm) to optimize their parameters. We showed on a simulated and real robot manipulators that our method was able to obtain better performing solutions that the classic hand-tuned Generalized Hierarchical Controller (developed in WP3).

In a second paper \cite{modugno2016learning} we focused on learning soft task priorities while guaranteeing that the generated behaviors are ``safe'', i.e., that they never violate any of the constraints of the robot and of the system. Indeed, CMA-ES was chosen because of its good exploration properties and ease of use (very few parameters to tune), however it does not take into account constraints violations during the exploration. In \cite{Modugno_PICRA_2016}, the solutions that were not feasible were simply discarded. In \cite{modugno2016learning} we investigated constrained stochastic optimization algorithms, focusing on three variants of CMA-ES: CMA-ES with vanilla constraints, CMA-ES with adaptive constraints and (1+1)-CMA-ES with covariance constrained adaptation. We compared the three algorithms on different benchmarks: classical constrained optimization problems with known solutions and two constrained robotics problems of our design. We found that the third method satisfies our requirements, specifically it always leads to solutions that never violate constraints. We showed the effectiveness of the approach by generating safe whole-body behaviors of iCubNancy01.

\subparagraph{Task compatibility optimization (T4.4) (UPMC: 1.87PM)}

As part of WP4 and WP3, UPMC has worked on improving its approach for task compatibility optimization. Indeed, highly redundant robots, such as humanoids, can execute multiple simultaneous tasks allowing them to perform complex whole-body behaviors. Unfortunately, tasks are generally planned without close consideration for the underlying controller being used, or the other tasks being executed. Because of this, tasks are often incompatible with one another and/or the system constraints, and cannot always be accomplished simultaneously. These incompatibilities can be managed using prioritization and gains, but tuning them is tedious. In this work, an alternative approach is taken and a task compatibility optimization loop which automatically improves task compatibility by modifying their trajectories using reinforcement learning is developed. To do so, the tasks are iteratively optimized by minimizing a compatibility cost, which measures the compatibility between one or more tasks, and the system constraints. Using two common scenarios, It is shown that task compatibility optimization results in whole-body behaviors which better match the original intent of the task combination without the need for manual tuning of task/controller parameters, heuristics, or re-planning. These results extend the contributions \cite{lober-HUMANOIDS2014} and \cite{lober_IROS2015} both in terms of achieved performances and computational efficiency. This work is described in \cite{deliverable33} and was submitted for presentation at a robotics journal~\cite{lober2017RAL-IROS}.

